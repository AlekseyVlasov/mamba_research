{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c22d4720-c7a0-479a-8237-3306fd1eb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c530615-c0a2-4800-a2c9-34f49a9a200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import pytorch_warmup as warmup\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from utils import print_model_size, fix_seed\n",
    "from models.MambaWithEmbeddings import MambaLMHeadModelWithEmbeddings\n",
    "from train_yelp_reviews import add_special_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54545f0f-251f-452b-8d4b-1bd5b6f1f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    # tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "160b4663-5ea5-4309-a4e2-cf5c7984eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "model_name = \"state-spaces/mamba-130m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80a24ae4-ce45-407b-a76c-20e2a718ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(seed)\n",
    "model = MambaLMHeadModelWithEmbeddings.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e3913eef-2333-4528-9fc2-8c513d9c4e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaLMHeadModelWithEmbeddings(\n",
       "  (backbone): MixerModelWithEmbeddings(\n",
       "    (embedding): Embedding(50280, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (norm): RMSNorm()\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=1536, out_features=80, bias=False)\n",
       "          (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
       "          (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
       "  (classification_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de737b-1557-4ea4-a2c2-e47b0e4c322a",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e0e4f9a-4cbf-46f6-a379-2938621ab49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def get_method(self, key, default=None):\n",
    "    return getattr(self, key, default)\n",
    "\n",
    "model.config.get = types.MethodType(get_method, model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd8e156f-1993-45f6-be7c-a3a34023b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaConfig(d_model=768, d_intermediate=0, n_layer=24, vocab_size=50277, ssm_cfg={}, attn_layer_idx=[], attn_cfg={}, rms_norm=True, residual_in_fp32=True, fused_add_norm=True, pad_vocab_size_multiple=8, tie_embeddings=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2c01ebfe-bf42-467b-a71d-7a37c074713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"in_proj\", \"x_proj\", \"dt_proj\", \"out_proj\"],\n",
    "    # target_modules=[\"in_proj\", \"out_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8d1f2a7a-97a6-4203-bb46-cfe2f0948f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaLMHeadModelWithEmbeddings(\n",
       "      (backbone): MixerModelWithEmbeddings(\n",
       "        (embedding): Embedding(50280, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x Block(\n",
       "            (norm): RMSNorm()\n",
       "            (mixer): Mamba(\n",
       "              (in_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "              (act): SiLU()\n",
       "              (x_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=80, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=80, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dt_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=48, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=48, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_f): RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
       "      (classification_head): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78f37680-c58d-4181-a6bb-ac83133b33b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаемых параметров: 1,794,048\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Обучаемых параметров: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce8772-d960-479f-b1b6-939d6f84b428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84b6c962-1688-4f48-8d09-ae9428600d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.freeze_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c37ad25-d079-4dc6-a735-b9da7369d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1919, -0.0347,  0.0941,  ..., -0.1357,  0.1383, -0.0218],\n",
       "        [ 0.0317,  0.0470, -0.2262,  ..., -0.1767,  0.0739,  0.0479],\n",
       "        [-0.0528,  0.1756,  0.1555,  ...,  0.2199, -0.1916, -0.0371],\n",
       "        ...,\n",
       "        [-0.1702, -0.0906, -0.0830,  ..., -0.0135, -0.0842,  0.0020],\n",
       "        [ 0.0432,  0.0286, -0.1470,  ...,  0.0472,  0.0670, -0.1609],\n",
       "        [ 0.1678,  0.0724,  0.0571,  ..., -0.1032, -0.0364,  0.0401]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone.layers[-1].mixer.out_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3eb43c5-9afa-400f-900f-6da7fc1b085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0009,  0.0087,  0.0269,  ...,  0.0269, -0.0181,  0.0178],\n",
       "        [-0.0118,  0.0232,  0.0009,  ...,  0.0321, -0.0164, -0.0025]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classification_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e1b151a1-42ba-412f-a21c-97ce9a1b7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем все слои кроме LoRA и классификационной головы\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" not in name and \"classification_head\" not in name:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b71cb3e6-97d0-4295-9cb2-5dc290c437ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаемых параметров: 1,795,586\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Обучаемых параметров: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c4877a18-b762-4d2b-b298-26be9a01ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_number = 0\n",
    "device = torch.device(f'cuda:{gpu_number}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "81e1cbdd-9641-4502-9830-4cd8552d2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "learning_rate = 0.0001\n",
    "tokens_num = 100\n",
    "period = 50\n",
    "warmup_percent = 0.05\n",
    "accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b35fd8ee-e24a-42d7-9f51-32271d3c2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   7%|███▌                                                 | 2378/35000 [14:16<3:15:53,  2.78it/s, Train Loss (batch)=0.878]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps  \u001b[38;5;66;03m# Для градиентного накопления\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m accumulated_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m accumulated_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_steps = num_epochs * len(train_dataloader) / accumulation_steps\n",
    "warmup_steps = int(warmup_percent * total_steps)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=5e-6)\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_steps)\n",
    "\n",
    "fix_seed(seed)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "    optimizer.zero_grad()\n",
    "    accumulated_loss = 0.0\n",
    "    accumulated_correct = 0\n",
    "    accumulated_total = 0\n",
    "    \n",
    "    for step, batch in enumerate(pbar):\n",
    "        inputs, labels = batch['input_ids'], batch['labels']\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs, num_last_tokens=1)\n",
    "        logits = outputs.logits[:, 0, :]\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        loss = loss / accumulation_steps  # Для градиентного накопления\n",
    "        loss.backward()\n",
    "        \n",
    "        accumulated_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        accumulated_total += labels.size(0)\n",
    "        accumulated_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with warmup_scheduler.dampening():\n",
    "                scheduler.step()\n",
    "            \n",
    "            total_train_loss += accumulated_loss\n",
    "            total_train += accumulated_total\n",
    "            correct_train += accumulated_correct\n",
    "            \n",
    "            # wandb.log({\n",
    "            #     \"train_loss_step\": accumulated_loss,\n",
    "            #     \"train_accuracy_step\": accumulated_correct / accumulated_total,\n",
    "            #     \"lr_step\": optimizer.param_groups[0]['lr']\n",
    "            # })\n",
    "            \n",
    "            pbar.set_postfix({\"Train Loss (batch)\": accumulated_loss})\n",
    "            \n",
    "            accumulated_loss = 0.0\n",
    "            accumulated_correct = 0\n",
    "            accumulated_total = 0\n",
    "    \n",
    "    train_accuracy_epoch = 100 * correct_train / total_train\n",
    "    # wandb.log({\n",
    "    #     \"train_loss_epoch\": total_train_loss / len(train_dataloader),\n",
    "    #     \"train_accuracy_epoch\": train_accuracy_epoch\n",
    "    # })\n",
    "    \n",
    "    val_batch_losses, val_accuracy = inference(model, val_loader, device, criterion=criterion, num_last_tokens=1)\n",
    "    val_loss = sum(val_batch_losses) / len(val_batch_losses)\n",
    "    \n",
    "    # wandb.log({\n",
    "    #     \"val_loss_epoch\": val_loss,\n",
    "    #     \"val_accuracy_epoch\": val_accuracy\n",
    "    # })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98ef72-3f05-43c3-a93d-e593d64a5d55",
   "metadata": {},
   "source": [
    "## Special token learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ca99528-aef2-40ca-b239-d054f32d66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "learning_rate = 0.0001\n",
    "tokens_num = 100\n",
    "period = 50\n",
    "warmup_percent = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96a3cf84-12b7-4ff7-9c23-dde94f111198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                                                            | 0/35000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transfer: 0.0002s\n",
      "Embedding Conversion: 0.0004s\n",
      "Add Special Token: 0.0007s\n",
      "Forward Pass: 0.4747s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                        | 1/35000 [00:01<10:50:33,  1.12s/it, Train Loss (batch)=1.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5788s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 1.0602s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0002s\n",
      "Add Special Token: 0.0005s\n",
      "Forward Pass: 0.3824s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                        | 2/35000 [00:02<10:01:09,  1.03s/it, Train Loss (batch)=1.48]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5732s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9592s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0002s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3825s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                         | 3/35000 [00:03<9:45:24,  1.00s/it, Train Loss (batch)=1.32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5745s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9602s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0001s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3825s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                         | 4/35000 [00:04<9:38:16,  1.01it/s, Train Loss (batch)=1.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5757s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9612s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0001s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3811s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                         | 5/35000 [00:05<9:34:43,  1.01it/s, Train Loss (batch)=1.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5763s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9605s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0001s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3849s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                         | 6/35000 [00:05<9:32:28,  1.02it/s, Train Loss (batch)=0.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5748s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9628s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0001s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3831s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                        | 7/35000 [00:06<9:30:58,  1.02it/s, Train Loss (batch)=0.892]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5759s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9625s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0002s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3843s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                        | 8/35000 [00:07<9:30:15,  1.02it/s, Train Loss (batch)=0.776]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5760s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9635s\n",
      "Data Transfer: 0.0001s\n",
      "Embedding Conversion: 0.0001s\n",
      "Add Special Token: 0.0004s\n",
      "Forward Pass: 0.3839s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training:   0%|                                                         | 9/35000 [00:08<9:38:08,  1.01it/s, Train Loss (batch)=1.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Pass & Optimization: 0.5764s\n",
      "Scheduler Update: 0.0001s\n",
      "Total Batch Time: 0.9633s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "special_token = torch.randn(1, tokens_num, model.config.d_model, requires_grad=True, device=device)\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [{'params': [special_token], 'lr': learning_rate},\n",
    "     {'params': model.parameters(), 'lr': learning_rate}],\n",
    ")\n",
    "\n",
    "total_steps = num_epochs * len(train_dataloader)\n",
    "warmup_steps = int(warmup_percent * total_steps)  # Calculate warmup steps as a percentage of total steps\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=5e-6)\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_steps)\n",
    "\n",
    "fix_seed(seed)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to evaluation mode\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "    for batch in pbar:\n",
    "        i += 1\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "        batch_start_time = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = batch['input_ids'], batch['labels']\n",
    "        \n",
    "        # Move data to the specified device\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Data Transfer: {time.time() - start:.4f}s\")\n",
    "\n",
    "        # Convert inputs to embeddings without tracking gradients\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        with torch.no_grad():\n",
    "            embedded_inputs = model.backbone.embedding(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Embedding Conversion: {time.time() - start:.4f}s\")\n",
    "\n",
    "        # Add special token\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        embedded_with_special = add_special_token(embedded_inputs, special_token, period, tokens_num)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Add Special Token: {time.time() - start:.4f}s\")\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        outputs = model(embedded_with_special, is_embeds=True, num_last_tokens=1)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Forward Pass: {time.time() - start:.4f}s\")\n",
    "        \n",
    "        logits = outputs.logits[:, 0, :]\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Backward Pass & Optimization: {time.time() - start:.4f}s\")\n",
    "        \n",
    "        # Apply warmup and scheduler updates\n",
    "        start = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        with warmup_scheduler.dampening():\n",
    "            scheduler.step()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Scheduler Update: {time.time() - start:.4f}s\")\n",
    "\n",
    "        # Accumulate training loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Calculate local train accuracy\n",
    "        train_accuracy_local = 100 * correct_train / total_train\n",
    "        \n",
    "        # Display the current loss for each training batch\n",
    "        pbar.set_postfix({\"Train Loss (batch)\": loss.item()})\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Total Batch Time: {time.time() - batch_start_time:.4f}s\")\n",
    "    break\n",
    "\n",
    "    # ---- Epoch-Based Logging ----\n",
    "    train_accuracy_epoch = 100 * correct_train / total_train\n",
    "\n",
    "    # ---- Validation phase after each epoch ----\n",
    "    val_batch_losses_local, val_accuracy = inference(\n",
    "        model, val_loader, device, criterion=criterion, num_last_tokens=1, special_token=special_token, period=period\n",
    "    )\n",
    "    val_loss = sum(val_batch_losses_local) / len(val_batch_losses_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cf3f924-36df-465b-9f79-6b461d1e38a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_token.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3801feaa-cb20-423d-ab1d-f9c777a3d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters number: 129136898\n",
      "Model size: 492.62 MB\n",
      "Model size: 0.48 GB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e4f5996-4973-4b59-a628-d5c29c2faabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters number: 1538\n",
      "Model size: 0.01 MB\n",
      "Model size: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model.classification_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b11fc3ed-478f-4fcb-88c0-c3ff8bdf0e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5818fb0-0241-4138-87ab-825adf86d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb247-cbf1-4027-9dbd-6cf698a54d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mamba_env)",
   "language": "python",
   "name": "mamba_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
